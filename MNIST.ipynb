{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/byebye/MNIST/blob/master/MNIST.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "G4LQtNNeoK3W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Install PyTorch"
      ]
    },
    {
      "metadata": {
        "id": "w3JisYqPc3O2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "07787d15-f553-4162-c5df-c978ffa2e59b"
      },
      "cell_type": "code",
      "source": [
        "# https://pytorch.org/\n",
        "!pip3 install torch torchvision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (0.3.0.post4)\r\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\r\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.14.3)\r\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch) (3.12)\r\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\r\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.1.0)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ycmjnko8oRna",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import PyTorch and check CUDA availability"
      ]
    },
    {
      "metadata": {
        "id": "hsFaGSqTlFd5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "use_cuda = True\n",
        "if use_cuda:\n",
        "  assert(torch.cuda.is_available())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8HPXKAY0obaM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Initialize parameters"
      ]
    },
    {
      "metadata": {
        "id": "uJw0h7qSoBas",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_size    = 784   # The image size = 28 x 28 = 784\n",
        "num_classes   = 10    # The number of output classes. In this case, from 0 to 9\n",
        "num_epochs    = 5     # The number of times entire dataset is trained\n",
        "train_size = 38000\n",
        "validation_size = 4000\n",
        "batch_size    = 64    # The size of input data took for one iteration\n",
        "learning_rate = 1e-3  # The speed of convergence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qj97J4d0ol0d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Download MNIST Dataset"
      ]
    },
    {
      "metadata": {
        "id": "wbdoBXlLonoX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "ae219fa8-81a9-4a58-e43f-638d6574cf9d"
      },
      "cell_type": "code",
      "source": [
        "train_dataset = dsets.MNIST(root='./data',\n",
        "                           train=True,\n",
        "                           transform=transforms.ToTensor(),\n",
        "                           download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./data',\n",
        "                           train=False,\n",
        "                           transform=transforms.ToTensor())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yfVKQOxxo3QB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load the Dataset\n",
        "\n",
        "**Note**: We shuffle the loading process of `train_dataset` to make the learning process independent of data order, but the order of `test_loader` remains so as to examine whether we can handle unspecified bias order of inputs.\n"
      ]
    },
    {
      "metadata": {
        "id": "4VrOJvCio5Sy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MAyuQNSFplH8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Build Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "JzXO9PtppkUE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "\n",
        "def build_cnn():\n",
        "    return nn.Sequential(\n",
        "#         nn.BatchNorm2d(1),\n",
        "        nn.Conv2d(1, 32, 5),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(32, 32, 5),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d((2, 2)),\n",
        "        nn.Dropout(0.25),\n",
        "\n",
        "        nn.Conv2d(32, 64, 3),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(64, 64, 3),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d((2, 2)),\n",
        "        nn.Dropout(0.25),\n",
        "\n",
        "        Flatten(),\n",
        "        nn.Linear(576, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.5),\n",
        "        nn.Linear(256, 10),\n",
        "        nn.Softmax(dim=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aLr1iNvgptlM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Instantiate the CNN"
      ]
    },
    {
      "metadata": {
        "id": "rze3jz3xpzB3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "net = build_cnn()\n",
        "if use_cuda:\n",
        "  net.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "thCyHKUWqJ3W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Choose the Loss Function and Optimizer\n",
        "\n",
        "Loss function (**criterion**) decides how the output can be compared to a class, which determines how good or bad the neural network performs. And the **optimizer** chooses a way to update the weight in order to converge to find the best weights in this neural network."
      ]
    },
    {
      "metadata": {
        "id": "B2PoTMHfqNM3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
        "\n",
        "optimizer = optim.RMSprop(params=net.parameters(), lr=learning_rate)\n",
        "\n",
        "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0FcGyxM3qciu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training the CNN Model"
      ]
    },
    {
      "metadata": {
        "id": "OZ1tRP830IY4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def is_last_epoch(epoch):\n",
        "    return epoch + 1 == num_epochs\n",
        "  \n",
        "predicted_train = []\n",
        "true_train = []\n",
        "predicted_test = []\n",
        "true_test = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_jW5sWaIqc_d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1252
        },
        "outputId": "ff4185f5-d92d-433c-88dd-e06439109c50"
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    net.train()\n",
        "    for i, (images, labels) in enumerate(train_loader):   # Load a batch of images with its (index, data, class)\n",
        "        # Conv2d expects data of shape (N, C, H, W) where N is batch size, C is channels, H is height, W is width\n",
        "        images = images.view(-1, 1, 28, 28) # change images dimension from [64, 768] to a matrix [64, 1, 28, 28]\n",
        "        images = Variable(images)\n",
        "        labels = Variable(labels)\n",
        "        \n",
        "        if use_cuda:\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "        \n",
        "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
        "        outputs = net(images)                             # Forward pass: compute the output class given a image\n",
        "        loss = criterion(outputs, labels)                 # Compute the loss: difference between the output class and the pre-given label\n",
        "        loss.backward()                                   # Backward pass: compute the weight\n",
        "        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n",
        "        \n",
        "        if (i+1) % 100 == 0:                              # Logging\n",
        "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
        "                 %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n",
        "    \n",
        "    net.eval() \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images.view(-1, 1, 28, 28)\n",
        "        images = Variable(images)\n",
        "\n",
        "        if use_cuda:\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1) # Choose the best class from the output: The class with the best score\n",
        "        total += labels.size(0)                    # Increment the total count\n",
        "        correct += (predicted == labels).sum()     # Increment the correct count\n",
        "        \n",
        "        if is_last_epoch(epoch):\n",
        "            global predicted_test\n",
        "            global true_test\n",
        "            true_test += labels.cpu().numpy().tolist()\n",
        "            predicted_test += predicted.data.numpy().tolist()\n",
        "    \n",
        "    test_acc = correct / total\n",
        "    lr_scheduler.step(test_acc)\n",
        "    print(test_acc)\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [100/937], Loss: 1.5550\n",
            "Epoch [1/5], Step [200/937], Loss: 1.4924\n",
            "Epoch [1/5], Step [300/937], Loss: 1.5237\n",
            "Epoch [1/5], Step [400/937], Loss: 1.5080\n",
            "Epoch [1/5], Step [500/937], Loss: 1.4768\n",
            "Epoch [1/5], Step [600/937], Loss: 1.4924\n",
            "Epoch [1/5], Step [700/937], Loss: 1.5080\n",
            "Epoch [1/5], Step [800/937], Loss: 1.4768\n",
            "Epoch [1/5], Step [900/937], Loss: 1.4768\n",
            "0.9831\n",
            "Epoch [2/5], Step [100/937], Loss: 1.5080\n",
            "Epoch [2/5], Step [200/937], Loss: 1.4612\n",
            "Epoch [2/5], Step [300/937], Loss: 1.4768\n",
            "Epoch [2/5], Step [400/937], Loss: 1.4924\n",
            "Epoch [2/5], Step [500/937], Loss: 1.4768\n",
            "Epoch [2/5], Step [600/937], Loss: 1.4924\n",
            "Epoch [2/5], Step [700/937], Loss: 1.5080\n",
            "Epoch [2/5], Step [800/937], Loss: 1.4926\n",
            "Epoch [2/5], Step [900/937], Loss: 1.4924\n",
            "0.9801\n",
            "Epoch [3/5], Step [100/937], Loss: 1.5080\n",
            "Epoch [3/5], Step [200/937], Loss: 1.5237\n",
            "Epoch [3/5], Step [300/937], Loss: 1.5237\n",
            "Epoch [3/5], Step [400/937], Loss: 1.5080\n",
            "Epoch [3/5], Step [500/937], Loss: 1.4924\n",
            "Epoch [3/5], Step [600/937], Loss: 1.4924\n",
            "Epoch [3/5], Step [700/937], Loss: 1.4768\n",
            "Epoch [3/5], Step [800/937], Loss: 1.4924\n",
            "Epoch [3/5], Step [900/937], Loss: 1.5080\n",
            "0.9833\n",
            "Epoch [4/5], Step [100/937], Loss: 1.4768\n",
            "Epoch [4/5], Step [200/937], Loss: 1.4924\n",
            "Epoch [4/5], Step [300/937], Loss: 1.4612\n",
            "Epoch [4/5], Step [400/937], Loss: 1.4924\n",
            "Epoch [4/5], Step [500/937], Loss: 1.5237\n",
            "Epoch [4/5], Step [600/937], Loss: 1.4922\n",
            "Epoch [4/5], Step [700/937], Loss: 1.5237\n",
            "Epoch [4/5], Step [800/937], Loss: 1.5080\n",
            "Epoch [4/5], Step [900/937], Loss: 1.4768\n",
            "0.9762\n",
            "Epoch [5/5], Step [100/937], Loss: 1.5080\n",
            "Epoch [5/5], Step [200/937], Loss: 1.4768\n",
            "Epoch [5/5], Step [300/937], Loss: 1.5705\n",
            "Epoch [5/5], Step [400/937], Loss: 1.4924\n",
            "Epoch [5/5], Step [500/937], Loss: 1.5080\n",
            "Epoch [5/5], Step [600/937], Loss: 1.5080\n",
            "Epoch [5/5], Step [700/937], Loss: 1.5393\n",
            "Epoch [5/5], Step [800/937], Loss: 1.5393\n",
            "Epoch [5/5], Step [900/937], Loss: 1.4768\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-412099d1a8bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mglobal\u001b[0m \u001b[0mtrue_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mtrue_test\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mpredicted_test\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mdata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cannot call .data on a torch.Tensor: did you intend to use autograd.Variable?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;31m# Numpy array interface, to support `numpy.asarray(tensor) -> ndarray`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cannot call .data on a torch.Tensor: did you intend to use autograd.Variable?"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "m5igm_ErvLFb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Plot Confusion Matrix"
      ]
    },
    {
      "metadata": {
        "id": "9-xenjk3vQ8Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes, normalize=False,\n",
        "                          title='Confusion matrix', cmap=plt.cm.Blues,\n",
        "                          filesave=None):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    np.set_printoptions(precision=2)\n",
        "    plt.figure(figsize=(7, 7))\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "\n",
        "    plt.xticks(tick_marks, classes)\n",
        "\n",
        "    yticks = []\n",
        "    for i in (range(cm.shape[0])):\n",
        "        acc = cm[i, i] / np.sum(cm[i])\n",
        "        yticks.append(\"{} (acc={:.10f})\".format(i, acc))\n",
        "\n",
        "    plt.yticks(tick_marks, yticks)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "    if filesave is None:\n",
        "        plt.tight_layout()\n",
        "#         plt.show()\n",
        "    else:\n",
        "        plt.savefig(filesave, bbox_inches='tight')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lwBoXbFgvYY_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# cnf_matrix = confusion_matrix(true_train, predicted_train)\n",
        "# plot_confusion_matrix(cm=cnf_matrix, classes=list(range(10)),\n",
        "#                       title='Train data confusion matrix')\n",
        "    \n",
        "cnf_matrix = confusion_matrix(true_test, predicted_test)\n",
        "plot_confusion_matrix(cm=cnf_matrix, classes=list(range(10)),\n",
        "                      title='Test data confusion matrix')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DbgvVDUorDXO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Testing the CNN Model\n",
        "\n",
        "Similar to training the neural network, we also need to load batches of test images and collect the outputs. The differences are that:\n",
        "\n",
        "1. No loss & weights calculation\n",
        "2. No weights update\n",
        "3. Has correct prediction calculation\n"
      ]
    },
    {
      "metadata": {
        "id": "vRvMlpuqrF1v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "net.eval() \n",
        "correct = 0\n",
        "total = 0\n",
        "for images, labels in test_loader:\n",
        "    images = Variable(images.view(-1, 28*28))\n",
        "    \n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "    \n",
        "    \n",
        "    outputs = net(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)  # Choose the best class from the output: The class with the best score\n",
        "    total += labels.size(0)                    # Increment the total count\n",
        "    correct += (predicted == labels).sum()     # Increment the correct count\n",
        "    \n",
        "print('Accuracy of the network on the 10K test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uNm9PGL-rKSy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Save the trained FNN Model for future use\n",
        "\n",
        "We save the trained model as a pickle that can be loaded and used later."
      ]
    },
    {
      "metadata": {
        "id": "uWBIPLxYrJRV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.save(net.state_dict(), 'cnn_model.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4aMz4RCOpIzN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Google Drive connection"
      ]
    },
    {
      "metadata": {
        "id": "S3ieQfzDe17_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d38cbd7b-b094-48b0-a7a5-c429184b9ea1"
      },
      "cell_type": "code",
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "# !pip install -U -q PyDrive\n",
        "# from pydrive.auth import GoogleAuth\n",
        "# from pydrive.drive import GoogleDrive\n",
        "# from google.colab import auth\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# # Authenticate and create the PyDrive client.\n",
        "# # This only needs to be done once per notebook.\n",
        "# auth.authenticate_user()\n",
        "# gauth = GoogleAuth()\n",
        "# gauth.credentials = GoogleCredentials.get_application_default()\n",
        "# drive = GoogleDrive(gauth)\n",
        "\n",
        "# # Download a file based on its file ID.\n",
        "# train_file_id = '12WsWKOlQ-IHlU4jK35xNJ3koG_CL6l5z'\n",
        "# test_file_id = '12MIA-FGEU4Ahtyqd_lDarSF0_cNenOj1'\n",
        "\n",
        "# train_file = drive.CreateFile({'id': train_file_id})\n",
        "# test_file = drive.CreateFile({'id': test_file_id})\n",
        "\n",
        "#print('Downloaded content \"{}\"'.format(train_file.GetContentString()[:100]))\n",
        "# print('Downloaded content \"{}\"'.format(test_file.GetContentString()))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloaded content \"label,pixel0,pixel1,pixel2,pixel3,pixel4,pixel5,pixel6,pixel7,pixel8,pixel9,pixel10,pixel11,pixel12,\"\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}